{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlba_ass2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXnMLoCUw9uo",
        "outputId": "766dca84-09c6-49fe-a31d-2f2e819bb806"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/ML datasets'\n",
        "%ls\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/ML datasets\n",
            " abalone.data               mnist_train.csv\n",
            " data_1.csv                 more_than_50k.csv\n",
            " data_2.csv                 output1.csv\n",
            "'Dataset Description.csv'   output.csv\n",
            " diabetes2.csv              output_log.csv\n",
            " DT_A_1.png                 output_reg.csv\n",
            " DT_B_1.png                 output_svm.csv\n",
            " DT-B-2-CC.png              population.csv\n",
            " DT-B-2-XX.png              PRSA_data_2010.1.1-2014.12.31.csv\n",
            " DT_C_1.pkl                'ROC Curve.png'\n",
            " fashion-mnist_test.csv     sigmoid\n",
            " fashion-mnist_train.csv    test.csv\n",
            " imagename.png              test_data.csv\n",
            " mbti_1.csv                 train.csv\n",
            " \u001b[0m\u001b[01;34mml-latest-small\u001b[0m/           train_data.csv\n",
            " mnist_test.csv             \u001b[01;34mweights\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjZN-U56v1tx"
      },
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from collections import Counter\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2EG27H0wp2h"
      },
      "source": [
        "#loading the training dataset\n",
        "data=pd.read_csv('train.csv')\n",
        "\n",
        "#loading the testing dataset\n",
        "data_test=pd.read_csv('test.csv')\n",
        "\n",
        "#storing IDs from testing dataset\n",
        "test_data_id= []\n",
        "for id,seq in zip(data_test['ID'], data_test[' Sequence']):\n",
        "    test_data_id.append(id)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5i7bbUWRx3G",
        "outputId": "d25b6d9b-89af-4e4b-b905-271eb921a4af"
      },
      "source": [
        "#Null values detection\n",
        "print(\"Number of null values:\")\n",
        "print(data.isnull().sum())\n",
        "#Train data is balanced\n",
        "print(\"Checking data imbalance:\")\n",
        "print(Counter(data[' Label']))\n",
        "print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of null values:\n",
            "Sequence    0\n",
            " Label      0\n",
            "dtype: int64\n",
            "Checking data imbalance:\n",
            "Counter({0: 3197, 1: 3197})\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmTFkQzPSioD",
        "outputId": "9f8d7120-5ab6-4f72-933e-025e48e53081"
      },
      "source": [
        "#Analysis of length of each sequence (to find max_length)\n",
        "import statistics\n",
        "\n",
        "#Analysis of length of each sequence in train dataset\n",
        "a=[]\n",
        "for seq in data['Sequence']:\n",
        "  a.append(len(seq))\n",
        "print(Counter(a))\n",
        "print(statistics.mean(a))\n",
        "\n",
        "#Analysis of length of each sequence in test dataset\n",
        "b=[]\n",
        "for seq in data_test[' Sequence']:\n",
        "  b.append(len(seq))\n",
        "print(Counter(b))\n",
        "print(statistics.mean(b))\n",
        "print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({15: 1035, 13: 631, 14: 600, 12: 550, 18: 395, 11: 393, 16: 393, 17: 384, 19: 357, 20: 344, 22: 303, 21: 268, 25: 268, 24: 245, 23: 228})\n",
            "16.69659055364404\n",
            "Counter({15: 208, 12: 203, 11: 170, 13: 159, 14: 153, 16: 94, 17: 78, 19: 78, 18: 75, 20: 71, 23: 69, 25: 63, 21: 61, 22: 59, 24: 57})\n",
            "16.161451814768462\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FKogUwaq4ht"
      },
      "source": [
        "#Pre-Processing\n",
        "\n",
        "#Integer Encoding\n",
        "char_dict= {'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19, 'X':20, 'Y': 21}\n",
        "def feature_extraction(data, column):\n",
        "  encode_list = []\n",
        "  for row in data[column].values:\n",
        "    row_encode = []\n",
        "    for code in row:\n",
        "      row_encode.append(char_dict.get(code, 0))\n",
        "    encode_list.append(np.array(row_encode))\n",
        "  #Sequence Padding \n",
        "  encode_list= pad_sequences(encode_list, maxlen=25, padding='post', truncating='post')\n",
        "  encode_list= feature_extraction_2(encode_list)\n",
        "  return encode_list\n",
        "\n",
        "#Feature Extraction: Binary Profiling, Frequency count, Molecular Weight\n",
        "molecular_weight_dict={1:89.1,15:174.2,12:132.1,3:133.1,2:121.2,4:147.1,14:146.2,6:75.1,7:155.2,8:131.2,10:131.2,9:146.2,11:149.2,5:165.2,13:115.1,16:105.1,17:119.1,19:204.2,21:181.2,18:117.1}\n",
        "def feature_extraction_2(e_list):\n",
        "  encode_list = []\n",
        "  for row in e_list:\n",
        "    row_encode = []\n",
        "    temp_array=[]\n",
        "    weight=0\n",
        "    for d in list(range(1, 22)):\n",
        "      temp_array.append((row == d).sum())\n",
        "    for code in row:\n",
        "      gene_string=[0 for k in range(21)]\n",
        "      gene_string[code-1]=1\n",
        "      temp_array.extend(gene_string)\n",
        "      weight+=molecular_weight_dict.get(code, 0)\n",
        "    row_encode.append(weight)\n",
        "    row_encode.extend(temp_array)\n",
        "    encode_list.append(np.array(row_encode))\n",
        "  return encode_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09lhXFV6sbNS"
      },
      "source": [
        "#Features and Labels splitting\n",
        "X_data = feature_extraction(data, 'Sequence')\n",
        "Y_data = data[' Label'].values\n",
        "X_data_test = feature_extraction(data_test, ' Sequence')\n",
        "\n",
        "#Splitting data into train and validation dataset to check accuracy\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_data, Y_data, test_size=0.2, random_state=123,stratify= Y_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu-2ctBulyEP"
      },
      "source": [
        "#Best Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI9sHoG6ctAD",
        "outputId": "224d6872-d959-4945-9a0c-560bca176113"
      },
      "source": [
        "#Best model: RandomForestRegressor\n",
        "\n",
        "print(\"Best model: RandomForestRegressor: \\n\")\n",
        "#min_samples_split=10 and n_estimators=100 to avoid overfitting and underfitting\n",
        "rf = RandomForestRegressor(n_estimators=100, n_jobs=-1) \n",
        "\n",
        "#GridSearchCV to apply  K-fold cross Validation and Hypeparameter tuning\n",
        "grid = GridSearchCV(estimator = rf, param_grid = {}, cv = 3, verbose=2, n_jobs = -1)\n",
        "grid.fit(X_data, Y_data)\n",
        "\n",
        "#Best estimator from GridSearchCV\n",
        "print(grid.best_estimator_)\n",
        "forest= grid.best_estimator_\n",
        "\n",
        "#Predicting values\n",
        "predictions = forest.predict(X_data_test)\n",
        "\n",
        "#Converting output into csv file\n",
        "output_data= []\n",
        "for i in range(len(predictions)):\n",
        "    output_data.append([test_data_id[i],predictions[i]])\n",
        "output_df=pd.DataFrame(output_data,columns=['ID','Label'])\n",
        "output_df.to_csv('output_RFR.csv', sep=',', index=False)\n",
        "print(\"\\n Output File: \\n\")\n",
        "print(output_df)\n",
        "print(\"\\n\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model: RandomForestRegressor: \n",
            "\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "RandomForestRegressor(n_jobs=-1)\n",
            "\n",
            " Output File: \n",
            "\n",
            "         ID  Label\n",
            "0     10001   0.28\n",
            "1     10002   0.14\n",
            "2     10003   0.41\n",
            "3     10004   0.17\n",
            "4     10005   0.29\n",
            "...     ...    ...\n",
            "1593  11594   0.50\n",
            "1594  11595   0.68\n",
            "1595  11596   0.73\n",
            "1596  11597   0.85\n",
            "1597  11598   0.73\n",
            "\n",
            "[1598 rows x 2 columns]\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BIZWs6ilruw"
      },
      "source": [
        "#Other Models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "day7QctcKGQT",
        "outputId": "63b8b8f6-e04e-4328-d0ed-07ce5ee4025f"
      },
      "source": [
        "#Best model:  RandomForestClassifier\n",
        "\n",
        "print(\"Model:  RandomForestClassifier \\n\")\n",
        "#min_samples_split=10 and n_estimators=100 to avoid overfitting and underfitting\n",
        "rc = RandomForestClassifier(n_estimators=100, n_jobs=-1) \n",
        "\n",
        "#GridSearchCV to apply  K-fold cross Validation and Hypeparameter tuning\n",
        "grid = GridSearchCV(estimator = rc, param_grid = {}, cv = 3, verbose=2, n_jobs = -1)\n",
        "grid.fit(X_train, Y_train)\n",
        "\n",
        "#Best estimator from GridSearchCV\n",
        "print(grid.best_estimator_)\n",
        "forestc= grid.best_estimator_\n",
        "\n",
        "#Chceking accuracy on val data\n",
        "Y_pred_val= forestc.predict(X_val)\n",
        "print(\"\\n Classification Report for Validation dataset: \\n\")\n",
        "print(classification_report(Y_val, Y_pred_val))\n",
        "\n",
        "\n",
        "#Predicting values\n",
        "predictions = forestc.predict(X_data_test)\n",
        "\n",
        "#Converting output into csv file\n",
        "output_data= []\n",
        "for i in range(len(predictions)):\n",
        "    output_data.append([test_data_id[i],predictions[i]])\n",
        "output_df=pd.DataFrame(output_data,columns=['ID','Label'])\n",
        "output_df.to_csv('output_RFC.csv', sep=',', index=False)\n",
        "print(\"\\n Output File: \\n\")\n",
        "print(output_df)\n",
        "print(\"\\n\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model:  RandomForestClassifier \n",
            "\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "RandomForestClassifier(n_jobs=-1)\n",
            "\n",
            " Classification Report for Validation dataset: \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.71      0.70       320\n",
            "           1       0.70      0.68      0.69       320\n",
            "\n",
            "    accuracy                           0.70       640\n",
            "   macro avg       0.70      0.70      0.70       640\n",
            "weighted avg       0.70      0.70      0.70       640\n",
            "\n",
            "\n",
            " Output File: \n",
            "\n",
            "         ID  Label\n",
            "0     10001      0\n",
            "1     10002      0\n",
            "2     10003      0\n",
            "3     10004      0\n",
            "4     10005      0\n",
            "...     ...    ...\n",
            "1593  11594      0\n",
            "1594  11595      1\n",
            "1595  11596      1\n",
            "1596  11597      1\n",
            "1597  11598      1\n",
            "\n",
            "[1598 rows x 2 columns]\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGPTr_lfc4mR",
        "outputId": "9f97f61e-c81e-4a8f-98b7-669c6e7306ed"
      },
      "source": [
        "#Model: Logistic Regression\n",
        "\n",
        "print(\"Model: Logistic Regression: \\n\")\n",
        "\n",
        "log = LogisticRegression(n_jobs=-1) \n",
        "\n",
        "#GridSearchCV to apply  K-fold cross Validation and Hypeparameter tuning\n",
        "grid = GridSearchCV(estimator = log, param_grid = {}, cv = 10, verbose=2, n_jobs = -1)\n",
        "grid.fit(X_train, Y_train)\n",
        "\n",
        "#Best estimator from GridSearchCV\n",
        "print(grid.best_estimator_)\n",
        "logistic= grid.best_estimator_\n",
        "\n",
        "#Chceking accuracy on val data\n",
        "Y_pred_val= logistic.predict(X_val)\n",
        "print(\"\\n Classification Report for Validation dataset: \\n\")\n",
        "print(classification_report(Y_val, Y_pred_val))\n",
        "\n",
        "\n",
        "#Predicting values\n",
        "predictions = logistic.predict(X_data_test)\n",
        "\n",
        "#Converting output into csv file\n",
        "output_data= []\n",
        "for i in range(len(predictions)):\n",
        "    output_data.append([test_data_id[i],predictions[i]])\n",
        "output_df=pd.DataFrame(output_data,columns=['ID','Label'])\n",
        "output_df.to_csv('output_Logistic.csv', sep=',', index=False)\n",
        "print(\"\\n Output File: \\n\")\n",
        "print(output_df)\n",
        "print(\"\\n\\n\\n\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Logistic Regression: \n",
            "\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "LogisticRegression(n_jobs=-1)\n",
            "\n",
            " Classification Report for Validation dataset: \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.70      0.70       320\n",
            "           1       0.70      0.69      0.70       320\n",
            "\n",
            "    accuracy                           0.70       640\n",
            "   macro avg       0.70      0.70      0.70       640\n",
            "weighted avg       0.70      0.70      0.70       640\n",
            "\n",
            "\n",
            " Output File: \n",
            "\n",
            "         ID  Label\n",
            "0     10001      0\n",
            "1     10002      0\n",
            "2     10003      0\n",
            "3     10004      0\n",
            "4     10005      0\n",
            "...     ...    ...\n",
            "1593  11594      1\n",
            "1594  11595      1\n",
            "1595  11596      1\n",
            "1596  11597      1\n",
            "1597  11598      1\n",
            "\n",
            "[1598 rows x 2 columns]\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ATGYTgTM2xI",
        "outputId": "687cf16b-34aa-43c1-d352-3b4e85b35b59"
      },
      "source": [
        "#Model: SVM\n",
        "\n",
        "print(\"Model: SVM: \\n\")\n",
        "svm = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "\n",
        "#training the model\n",
        "svm.fit(X_train, Y_train)\n",
        "\n",
        "#Chceking accuracy on val data\n",
        "Y_pred_val= svm.predict(X_val)\n",
        "print(\"\\n Classification Report for Validation dataset: \\n\")\n",
        "print(classification_report(Y_val, Y_pred_val))\n",
        "\n",
        "#Predicting values\n",
        "predictions = svm.predict(X_data_test)\n",
        "\n",
        "#Converting output into csv file\n",
        "output_data= []\n",
        "for i in range(len(predictions)):\n",
        "    output_data.append([test_data_id[i],int(predictions[i])])\n",
        "output_df=pd.DataFrame(output_data,columns=['ID','Label'])\n",
        "output_df.to_csv('output_SVM.csv', sep=',', index=False)\n",
        "print(\"\\n Output File: \\n\")\n",
        "print(output_df)\n",
        "print(\"\\n\\n\\n\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: SVM: \n",
            "\n",
            "\n",
            " Classification Report for Validation dataset: \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.68      0.70       320\n",
            "           1       0.69      0.72      0.71       320\n",
            "\n",
            "    accuracy                           0.70       640\n",
            "   macro avg       0.70      0.70      0.70       640\n",
            "weighted avg       0.70      0.70      0.70       640\n",
            "\n",
            "\n",
            " Output File: \n",
            "\n",
            "         ID  Label\n",
            "0     10001      1\n",
            "1     10002      0\n",
            "2     10003      0\n",
            "3     10004      0\n",
            "4     10005      0\n",
            "...     ...    ...\n",
            "1593  11594      0\n",
            "1594  11595      1\n",
            "1595  11596      1\n",
            "1596  11597      1\n",
            "1597  11598      1\n",
            "\n",
            "[1598 rows x 2 columns]\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZIVeQWo_1IU",
        "outputId": "5d8ef6c8-3365-4054-c1ea-242d50727b8b"
      },
      "source": [
        "#Model: Kth Nearest Neighbour\n",
        "\n",
        "print(\"Model: KNN \\n\")\n",
        "knn = KNeighborsClassifier(n_neighbors=20)\n",
        "\n",
        "#training the model\n",
        "knn.fit(X_train, Y_train)\n",
        "\n",
        "#Chceking accuracy on val data\n",
        "Y_pred_val= knn.predict(X_val)\n",
        "print(\"\\n Classification Report for Validation dataset: \\n\")\n",
        "print(classification_report(Y_val, Y_pred_val))\n",
        "\n",
        "#Predicting values\n",
        "predictions = knn.predict(X_data_test)\n",
        "\n",
        "#Converting output into csv file\n",
        "output_data= []\n",
        "for i in range(len(predictions)):\n",
        "    output_data.append([test_data_id[i],int(predictions[i])])\n",
        "output_df=pd.DataFrame(output_data,columns=['ID','Label'])\n",
        "output_df.to_csv('output_KNN.csv', sep=',', index=False)\n",
        "print(\"\\n Output File: \\n\")\n",
        "print(output_df)\n",
        "print(\"\\n\\n\\n\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: KNN \n",
            "\n",
            "\n",
            " Classification Report for Validation dataset: \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.62      0.61       320\n",
            "           1       0.60      0.56      0.58       320\n",
            "\n",
            "    accuracy                           0.59       640\n",
            "   macro avg       0.59      0.59      0.59       640\n",
            "weighted avg       0.59      0.59      0.59       640\n",
            "\n",
            "\n",
            " Output File: \n",
            "\n",
            "         ID  Label\n",
            "0     10001      0\n",
            "1     10002      0\n",
            "2     10003      0\n",
            "3     10004      0\n",
            "4     10005      0\n",
            "...     ...    ...\n",
            "1593  11594      0\n",
            "1594  11595      1\n",
            "1595  11596      1\n",
            "1596  11597      0\n",
            "1597  11598      1\n",
            "\n",
            "[1598 rows x 2 columns]\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}